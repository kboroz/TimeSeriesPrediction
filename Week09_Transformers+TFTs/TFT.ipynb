{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "453ff0d7",
      "metadata": {
        "id": "453ff0d7"
      },
      "source": [
        "Example was taken from\n",
        "https://unit8co.github.io/darts/examples/13-TFT-examples.html"
      ]
    },
    {
      "metadata": {
        "id": "3c0c38b4ef3d0bc"
      },
      "cell_type": "markdown",
      "source": [
        "# 1. Setup"
      ],
      "id": "3c0c38b4ef3d0bc"
    },
    {
      "cell_type": "code",
      "id": "153c080c",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-06-12T13:02:18.235463Z",
          "start_time": "2024-06-12T13:02:16.738838Z"
        },
        "id": "153c080c"
      },
      "source": [
        "# fix python path if working locally\n",
        "# from utils import fix_pythonpath_if_working_locally\n",
        "# fix_pythonpath_if_working_locally()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install darts"
      ],
      "metadata": {
        "id": "NtajC6AvqMKE"
      },
      "id": "NtajC6AvqMKE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "id": "cdc833de",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-06-12T13:11:07.437478Z",
          "start_time": "2024-06-12T13:11:07.360982Z"
        },
        "id": "cdc833de"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from darts import TimeSeries, concatenate\n",
        "from darts.dataprocessing.transformers import Scaler\n",
        "from darts.models import TFTModel\n",
        "from darts.metrics import mape\n",
        "from darts.utils.statistics import check_seasonality, plot_acf\n",
        "from darts.datasets import AirPassengersDataset, IceCreamHeaterDataset\n",
        "from darts.utils.timeseries_generation import datetime_attribute_timeseries\n",
        "from darts.utils.likelihood_models import QuantileRegression\n",
        "\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import logging\n",
        "\n",
        "logging.disable(logging.CRITICAL)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "id": "30927699",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-06-12T13:11:07.516387Z",
          "start_time": "2024-06-12T13:11:07.440090Z"
        },
        "id": "30927699"
      },
      "source": [
        "# before starting, we define some constants\n",
        "NUM_SAMPLES = 200\n",
        "\n",
        "FIGSIZE = (9, 6)\n",
        "LOWEST_Q, LOW_Q, HIGH_Q, HIGHEST_Q = 0.01, 0.1, 0.9, 0.99\n",
        "LABEL_Q_OUTER = f\"{int(LOWEST_Q * 100)}-{int(HIGHEST_Q * 100)}th percentiles\"\n",
        "LABEL_Q_INNER = f\"{int(LOW_Q * 100)}-{int(HIGH_Q * 100)}th percentiles\""
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "b4ee1e98",
      "metadata": {
        "id": "b4ee1e98"
      },
      "source": [
        "## 2. Ice Cream Heater Dataset\n",
        "\n",
        "**== Monthly sales of heaters and ice cream between January 2004 and June 2020.**"
      ]
    },
    {
      "cell_type": "code",
      "id": "e008b53d",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-06-12T13:11:08.300493Z",
          "start_time": "2024-06-12T13:11:07.518483Z"
        },
        "id": "e008b53d"
      },
      "source": [
        "series_ice_heater = IceCreamHeaterDataset().load()\n",
        "\n",
        "plt.figure(figsize=FIGSIZE)\n",
        "series_ice_heater.plot()\n",
        "\n",
        "print(check_seasonality(series_ice_heater[\"ice cream\"], max_lag=36))\n",
        "print(check_seasonality(series_ice_heater[\"heater\"], max_lag=36))\n",
        "\n",
        "plt.figure(figsize=FIGSIZE)\n",
        "plot_acf(series_ice_heater[\"ice cream\"], 12, max_lag=36)  # ~1 year seasonality"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "146e6bf90a099fab"
      },
      "cell_type": "markdown",
      "source": [
        "## 2.1. Plot Interpretation:\n",
        "### Plot 1\n",
        "- **Seasonal Patterns:** Both series show clear seasonal patterns.\n",
        "  - The ice cream sales peak during warmer months\n",
        "  - Heater sales peak during colder months --> shows inverse seasonality.\n",
        "\n",
        "- **Trend:** Both series show an increasing trend over the years --> growth in sales/ demand for both products.\n",
        "\n",
        "### Plot 2\n",
        "- **Autocorrelation:** The ACF plot shows a clear seasonality of 12 months for ice cream series, which shows the correlation of the series with its own past values over different lags.\n",
        "\n",
        "\n",
        "- **Seasonality Detection:** The plot confirms a strong seasonal component, with significant autocorrelations around lags that correspond to seasonal periods (~12 months)."
      ],
      "id": "146e6bf90a099fab"
    },
    {
      "metadata": {
        "id": "e195f768b1150a4b"
      },
      "cell_type": "markdown",
      "source": [],
      "id": "e195f768b1150a4b"
    },
    {
      "metadata": {
        "id": "3386ae482a4c2708"
      },
      "cell_type": "markdown",
      "source": [
        "## 3. Data Transformation\n",
        "\n",
        "1. **Convert Monthly Sales to Average Daily Sales per Month:**\n",
        "   - Convert the monthly sales to average daily sales per month to make the series more granular.\n",
        "\n",
        "2. **Train-Validation Split:**\n",
        "    - Define the training and validation sets using the transformed series.\n",
        "        - The training set includes data until 2 years before the end of the series.\n",
        "                \n",
        "3. **Data Transformation:**\n",
        "   - Transform the data using the `Scaler` transformer.\n",
        "      - The transformer standardizes the data by subtracting the mean and dividing by the standard deviation.\n",
        "\n",
        "4. **Define Past Covariates:**\n",
        "    - Use the heater sales as past covariates (=exogenous variable) for the ice cream sales.\n",
        "        - The model will use the past heater sales to predict future ice cream sales.\n",
        "        \n",
        "    - Transform the covariates using the `Scaler` transformer."
      ],
      "id": "3386ae482a4c2708"
    },
    {
      "cell_type": "code",
      "id": "014b0073",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-06-12T13:02:26.768474Z",
          "start_time": "2024-06-12T13:02:26.644292Z"
        },
        "id": "014b0073"
      },
      "source": [
        "# convert monthly sales to average daily sales per month\n",
        "converted_series = []\n",
        "for col in [\"ice cream\", \"heater\"]:\n",
        "    # Convert the Index to a Series so Darts can process it\n",
        "    days_in_month_series = pd.Series(\n",
        "        series_ice_heater.time_index.days_in_month,\n",
        "        index=series_ice_heater.time_index\n",
        "    )\n",
        "\n",
        "    converted_series.append(\n",
        "        series_ice_heater[col] / TimeSeries.from_series(days_in_month_series)\n",
        "    )\n",
        "converted_series = concatenate(converted_series, axis=1)\n",
        "converted_series = converted_series[pd.Timestamp(\"20100101\") :]\n",
        "\n",
        "# define train/validation cutoff time\n",
        "forecast_horizon_ice = 12\n",
        "training_cutoff_ice = converted_series.time_index[-(2 * forecast_horizon_ice)]\n",
        "\n",
        "# use ice cream sales as target, create train and validation sets and transform data\n",
        "series_ice = converted_series[\"ice cream\"]\n",
        "train_ice, val_ice = series_ice.split_before(training_cutoff_ice)\n",
        "transformer_ice = Scaler()\n",
        "train_ice_transformed = transformer_ice.fit_transform(train_ice)\n",
        "val_ice_transformed = transformer_ice.transform(val_ice)\n",
        "series_ice_transformed = transformer_ice.transform(series_ice)\n",
        "\n",
        "# use heater sales as past covariates and transform data\n",
        "covariates_heat = converted_series[\"heater\"]\n",
        "cov_heat_train, cov_heat_val = covariates_heat.split_before(training_cutoff_ice)\n",
        "transformer_heat = Scaler()\n",
        "transformer_heat.fit(cov_heat_train)\n",
        "covariates_heat_transformed = transformer_heat.transform(covariates_heat)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-06-12T13:02:26.838876Z",
          "start_time": "2024-06-12T13:02:26.770205Z"
        },
        "id": "65fb511b94a57"
      },
      "cell_type": "code",
      "source": [
        "# Check the end times of the series\n",
        "print(f\"Train end time: {train_ice.end_time()}\")\n",
        "print(f\"Validation end time: {val_ice.end_time()}\")"
      ],
      "id": "65fb511b94a57",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "eb90147d5391d31b"
      },
      "cell_type": "markdown",
      "source": [
        "## 4. Model Training\n",
        "**Temporal Fusion Transformer (TFT):**\n",
        "- **Combines an encoder-decoder** architecture with **multi-head attention mechanisms** and **gating mechanisms** like Gated Residual Networks (GRNs) to **process historical and future covariates simultaneously**.\n",
        "- Integrates static covariates, handles complex temporal dependencies, and dynamically weighs the importance of different time steps and features to generate multi-horizon forecasts.\n",
        "\n",
        "**Define the Model:**\n",
        "   - Use the `TFTModel` model to train the model.\n",
        "       - The model uses the last 3 years of data as past input data.\n",
        "       - The model includes a single LSTM layer with 32 hidden units and a dropout rate of 0.1.\n",
        "       - The model uses the heater sales as past covariates.\n",
        "       - The model uses the month as a known future variable (cyclic encoders)\n",
        "       - The model uses dropout regularization to prevent overfitting.       \n",
        "       - The model is trained for 300 epochs with a batch size of 16 and a learning rate of 1e-3 (0.0001).\n",
        "       "
      ],
      "id": "eb90147d5391d31b"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-06-12T13:04:30.247623Z",
          "start_time": "2024-06-12T13:02:26.840907Z"
        },
        "id": "75ecc1a4bfb4f5d5"
      },
      "cell_type": "code",
      "source": [
        "# use the last 3 years as past input data\n",
        "input_chunk_length_ice = 36\n",
        "\n",
        "# use `add_encoders` as we don't have future covariates\n",
        "my_model_ice = TFTModel(\n",
        "    input_chunk_length=input_chunk_length_ice,\n",
        "    output_chunk_length=forecast_horizon_ice,\n",
        "    hidden_size=32,\n",
        "    lstm_layers=1,\n",
        "    batch_size=16,\n",
        "    n_epochs=300,\n",
        "    dropout=0.1,\n",
        "    add_encoders={\"cyclic\": {\"future\": [\"month\"]}}, #known future variable: month\n",
        "    add_relative_index=False,\n",
        "    optimizer_kwargs={\"lr\": 1e-3},\n",
        "    random_state=42,\n",
        ")\n",
        "\n",
        "# fit the model with past covariates\n",
        "my_model_ice.fit(\n",
        "    train_ice_transformed,\n",
        "    past_covariates=covariates_heat_transformed,\n",
        "    verbose=True\n",
        ")"
      ],
      "id": "75ecc1a4bfb4f5d5",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "789a863f56a24d0"
      },
      "cell_type": "markdown",
      "source": [
        "## 5. Model Evaluation\n",
        "**Evaluate the Model:**\n",
        "   - Evaluate the model using the validation set.\n",
        "   - Compute the Mean Absolute Percentage Error (MAPE) between the actual and predicted values.\n",
        "   - Plot the actual and predicted values for the validation set.\n",
        "\n",
        "#### *Note: The cell with eval_model() function was missing from the notebook. I recreated it below.*"
      ],
      "id": "789a863f56a24d0"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-06-12T13:04:30.411924Z",
          "start_time": "2024-06-12T13:04:30.251347Z"
        },
        "id": "223f182ebcf034c1"
      },
      "cell_type": "code",
      "source": [
        "def eval_model(model, n, actual_series, val_series):\n",
        "    pred_series = model.predict(n=n, num_samples=NUM_SAMPLES)\n",
        "\n",
        "    # plot actual series\n",
        "    plt.figure(figsize=FIGSIZE)\n",
        "    actual_series[: pred_series.end_time()].plot(label=\"actual\")\n",
        "\n",
        "    # plot prediction with quantile ranges\n",
        "    pred_series.plot(\n",
        "        low_quantile=LOWEST_Q, high_quantile=HIGHEST_Q, label=LABEL_Q_OUTER\n",
        "    )\n",
        "    pred_series.plot(low_quantile=LOW_Q, high_quantile=HIGH_Q, label=LABEL_Q_INNER)\n",
        "\n",
        "    plt.title(\"MAPE: {:.2f}%\".format(mape(val_series, pred_series)))\n",
        "    plt.legend()\n"
      ],
      "id": "223f182ebcf034c1",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-06-12T13:04:31.952454Z",
          "start_time": "2024-06-12T13:04:30.413965Z"
        },
        "id": "39b5b37404a29b4"
      },
      "cell_type": "code",
      "source": [
        "# evaluate the model\n",
        "n = 24\n",
        "eval_model(\n",
        "    model=my_model_ice,\n",
        "    n=n,\n",
        "    actual_series=series_ice_transformed[\n",
        "        train_ice.end_time() - (2 * n - 1) * train_ice.freq :\n",
        "    ],\n",
        "    val_series=val_ice_transformed,\n",
        ")"
      ],
      "id": "39b5b37404a29b4",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "d73e96d1f365862f"
      },
      "cell_type": "markdown",
      "source": [
        "1.4.1. Model Evaluation: Plot Interpretation\n",
        "- **Actual vs. Predicted Values:** The plot shows the actual and predicted ice cream sales for the validation set.\n",
        "- **Quantile Ranges:** The plot includes the 1-99th and 10-90th percentiles of the predicted values.\n",
        "- **Mean Absolute Percentage Error (MAPE):** The MAPE is computed between the actual and predicted values.\n",
        "    - The model achieves a MAPE of 7.30% on the validation set, indicating that it it is off by 7.30% on average.\n",
        "- **Prediction Accuracy:** The model accurately captures the seasonal patterns and trends in the ice cream sales.\n"
      ],
      "id": "d73e96d1f365862f"
    },
    {
      "metadata": {
        "id": "5f94c8b4ccd28691"
      },
      "cell_type": "markdown",
      "source": [
        "## 6. Backtesting\n",
        "**Backtesting: simulating how the model would have performed in real-time**\n",
        "\n",
        "   - **Historical Forecasts:** Compute backtest predictions using the historical_forecasts method of the TFT model.\n",
        "      - This method allows for rolling forecasts over the validation period. That means the model can be **retrained at each step using the actual data up to that point**.\n",
        "\n",
        "   - Evaluate the backtest predictions and plot the actual and predicted values.\n",
        "\n",
        "\n",
        "**Why is TFT particularly advantageous for backtesting?**\n",
        "\n",
        "- **Handling Temporal Dynamics:**\n",
        "- TFT captures complex temporal patterns by incorporating both past and future covariates -> important for datasets with strong seasonal and trend components.\n",
        "\n",
        "\n",
        "- **Multi-Horizon Forecasting:**\n",
        "- TFT can forecast multiple time steps ahead --> suitable for backtesting over different forecast horizons\n",
        "\n",
        "\n",
        "**Explanation of Parameters:**\n",
        "- **start:** The start time for the backtesting period, which is the end of the training period.\n",
        "\n",
        "\n",
        "- **forecast_horizon:** The forecast horizon for the backtesting period, which is 12 months.\n",
        "\n",
        "\n",
        "- **stride:** The stride parameter in backtesting controls the frequency of the predictions. A stride of 1 means predictions are made at every time step, whereas a larger stride skips some steps, making the backtest less granular but faster.\n",
        "\n",
        "\n",
        "- **retrain:** The retrain parameter controls whether the model is retrained at each step during backtesting. Setting retrain to False means the model is trained only once at the beginning.\n",
        "\n",
        "\n",
        "- **overlap_end:** allows the model to use overlapping windows for predictions, which can help in generating more predictions but may introduce some dependency between them.\n",
        "\n",
        "\n",
        "- **last_points_only:** Whether to use only the last points of the series for backtesting. If set to True, the model is retrained at each step using the actual data up to that point. If set to False, the model is retrained at each step using the entire series up to that point.\n"
      ],
      "id": "5f94c8b4ccd28691"
    },
    {
      "cell_type": "code",
      "id": "00e3acd0",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-06-12T13:04:32.753178Z",
          "start_time": "2024-06-12T13:04:31.955081Z"
        },
        "id": "00e3acd0"
      },
      "source": [
        "# Compute the backtest predictions\n",
        "last_points_only = False\n",
        "backtest_series_ice = my_model_ice.historical_forecasts(\n",
        "    series_ice_transformed,\n",
        "    num_samples=NUM_SAMPLES,\n",
        "    start=training_cutoff_ice,\n",
        "    forecast_horizon=forecast_horizon_ice,\n",
        "    stride=1 if last_points_only else forecast_horizon_ice,\n",
        "    retrain=False,\n",
        "    last_points_only=last_points_only,\n",
        "    overlap_end=True,\n",
        "    verbose=True,\n",
        ")\n",
        "\n",
        "backtest_series_ice = (\n",
        "    concatenate(backtest_series_ice)\n",
        "    if isinstance(backtest_series_ice, list)\n",
        "    else backtest_series_ice\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "id": "733f366c",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-06-12T13:04:32.825792Z",
          "start_time": "2024-06-12T13:04:32.755529Z"
        },
        "id": "733f366c"
      },
      "source": [
        "def eval_backtest(backtest_series, actual_series, horizon, start, transformer):\n",
        "    plt.figure(figsize=FIGSIZE)\n",
        "    actual_series.plot(label=\"actual\")\n",
        "    backtest_series.plot(\n",
        "        low_quantile=LOWEST_Q, high_quantile=HIGHEST_Q, label=LABEL_Q_OUTER\n",
        "    )\n",
        "    backtest_series.plot(low_quantile=LOW_Q, high_quantile=HIGH_Q, label=LABEL_Q_INNER)\n",
        "    plt.legend()\n",
        "    plt.title(f\"Backtest, starting {start}, {horizon}-months horizon\")\n",
        "    print(\n",
        "        \"MAPE: {:.2f}%\".format(\n",
        "            mape(\n",
        "                transformer.inverse_transform(actual_series),\n",
        "                transformer.inverse_transform(backtest_series),\n",
        "            )\n",
        "        )\n",
        "    )"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "21c080286203fa22"
      },
      "cell_type": "markdown",
      "source": [
        "### 6.1. Backtesting without Retraining"
      ],
      "id": "21c080286203fa22"
    },
    {
      "cell_type": "code",
      "id": "ab6f219e",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-06-12T13:04:33.448296Z",
          "start_time": "2024-06-12T13:04:32.828092Z"
        },
        "id": "ab6f219e"
      },
      "source": [
        "eval_backtest(\n",
        "    backtest_series=backtest_series_ice,\n",
        "    actual_series=series_ice_transformed[\n",
        "        train_ice.start_time() - 2 * forecast_horizon_ice * train_ice.freq :\n",
        "    ],\n",
        "    horizon=forecast_horizon_ice,\n",
        "    start=training_cutoff_ice,\n",
        "    transformer=transformer_ice,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "c376f9e92b366f85"
      },
      "cell_type": "markdown",
      "source": [
        "### **MAPE** for the backtesting period is lower than the previous prediction, with a value of 4.86%\n",
        "\n",
        "**Potential Reasons:**\n",
        "- Even though the model is not retrained, the historical data used for backtesting is closer in time to the training data than the validation set.\n",
        "\n"
      ],
      "id": "c376f9e92b366f85"
    },
    {
      "metadata": {
        "id": "3de6d0f8344d55f6"
      },
      "cell_type": "markdown",
      "source": [
        "### 6.2. Backtesting with Retraining"
      ],
      "id": "3de6d0f8344d55f6"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-06-12T13:11:05.486051Z",
          "start_time": "2024-06-12T13:04:33.450669Z"
        },
        "id": "e53cc36c1329f37e"
      },
      "cell_type": "code",
      "source": [
        "# Compute the backtest predictions\n",
        "last_points_only = False\n",
        "backtest_series_ice = my_model_ice.historical_forecasts(\n",
        "    series_ice_transformed,\n",
        "    num_samples=NUM_SAMPLES,\n",
        "    start=training_cutoff_ice,\n",
        "    forecast_horizon=forecast_horizon_ice,\n",
        "    stride=1 if last_points_only else forecast_horizon_ice,\n",
        "    retrain=True,\n",
        "    last_points_only=last_points_only,\n",
        "    overlap_end=True,\n",
        "    verbose=True,\n",
        ")\n",
        "\n",
        "backtest_series_ice = (\n",
        "    concatenate(backtest_series_ice)\n",
        "    if isinstance(backtest_series_ice, list)\n",
        "    else backtest_series_ice\n",
        ")"
      ],
      "id": "e53cc36c1329f37e",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-06-12T13:11:06.080840Z",
          "start_time": "2024-06-12T13:11:05.492627Z"
        },
        "id": "e9f65f2982f36fcf"
      },
      "cell_type": "code",
      "source": [
        "eval_backtest(\n",
        "    backtest_series=backtest_series_ice,\n",
        "    actual_series=series_ice_transformed[\n",
        "        train_ice.start_time() - 2 * forecast_horizon_ice * train_ice.freq :\n",
        "    ],\n",
        "    horizon=forecast_horizon_ice,\n",
        "    start=training_cutoff_ice,\n",
        "    transformer=transformer_ice,\n",
        ")"
      ],
      "id": "e9f65f2982f36fcf",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "641cfedbb2439a5c"
      },
      "cell_type": "markdown",
      "source": [
        "#### **MAPE** for the backtesting period is 4.17% with retraining which is slightly lower than the previous backtest without retraining.\n",
        "#### However, the training time was significantly longer due to retraining at each step."
      ],
      "id": "641cfedbb2439a5c"
    },
    {
      "cell_type": "code",
      "id": "3d17f3e3",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-06-12T13:11:06.245538Z",
          "start_time": "2024-06-12T13:11:06.086673Z"
        },
        "id": "3d17f3e3"
      },
      "source": [
        "from darts.explainability import TFTExplainer\n",
        "explainer = TFTExplainer(my_model_ice)\n",
        "explainability_result = explainer.explain()\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "9f2dd62c74b53a14"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "# **7. Explainability Analysis:**\n",
        "## **7.1. Variable Importance**\n",
        "\n",
        "**Encoder Variable Importance**\n",
        "\n",
        "-Historical Data Processing: The encoder processes past data, identifying which historical variables are most influential in understanding the time series' current state.\n",
        "\n",
        "**Decoder Variable Importance**\n",
        "\n",
        "-Forecast Generation: The decoder uses the encoded historical data and future inputs to generate forecasts.\n"
      ],
      "id": "9f2dd62c74b53a14"
    },
    {
      "cell_type": "code",
      "id": "9fd2af26",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-06-12T13:11:06.714553Z",
          "start_time": "2024-06-12T13:11:06.247912Z"
        },
        "id": "9fd2af26"
      },
      "source": [
        "explainer.plot_variable_selection(explainability_result)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "c4bbd97c6aaaea15"
      },
      "cell_type": "markdown",
      "source": [],
      "id": "c4bbd97c6aaaea15"
    },
    {
      "metadata": {
        "id": "1da1d440cb61bbbb"
      },
      "cell_type": "markdown",
      "source": [
        "### 7.1.1. Interpretation:\n",
        "\n",
        "**Encoder Variable Importance:**\n",
        "\n",
        "- **ice cream sales** are the most important features for the model\n",
        "    - Autorregressive component, not surprising\n",
        "\n",
        "- **darts_enc_fc_cyc_month_cos_futcov**: probably represents a cyclical (seasonal) feature based on the cosine of the month index.\n",
        "    - moderate importance --> seasonality plays a significant role in the model's understanding of past data.\n",
        "  \n",
        "- **heater_pastcov**: past values of heater sales have some importance.\n",
        "    - This implies that heater sales have a predictive relationship with ice cream sales\n",
        "        - possibly due to inverse seasonal patterns, or because both trends are rising over time (see plot 1 in the notebook)\n",
        "    \n",
        "- **darts_enc_fc_cyc_month_sin_futcov**: another cyclical feature based on the sine of the month index. It has low importance in the encoder.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "**Decoder Variable Importance:**\n",
        "\n",
        "- **darts_enc_fc_cyc_month_cos_futcov**:\n",
        "    - highest importance in the decoder.\n",
        "        - indicates that seasonality is critical for generating future forecasts.\n",
        "\n",
        "\n",
        "- **darts_enc_fc_cyc_month_sin_futcov**:\n",
        "     - reinforces importance of seasonality in the decoder."
      ],
      "id": "1da1d440cb61bbbb"
    },
    {
      "metadata": {
        "id": "149bd50d215f6797"
      },
      "cell_type": "markdown",
      "source": [
        "## 7.2. Attention Analysis\n",
        "\n",
        "### 7.2.1. Mean Attention\n",
        "\n",
        "The mean attention plot shows how the model's attention mechanism assigns importance to different time steps relative to the prediction point.\n",
        "\n",
        "Index relative to first prediction point: The x-axis represents the time steps relative to the prediction point, with 0 being the point at which predictions start.\n",
        "\n",
        "Attention: The y-axis represents the attention weights assigned to different time steps."
      ],
      "id": "149bd50d215f6797"
    },
    {
      "cell_type": "code",
      "id": "8dace623",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-06-12T13:11:06.996643Z",
          "start_time": "2024-06-12T13:11:06.716666Z"
        },
        "id": "8dace623"
      },
      "source": [
        "explainer.plot_attention(explainability_result, plot_type=\"time\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "872dcf5452e5c2a"
      },
      "cell_type": "markdown",
      "source": [
        "### 7.2.1.1. Interpretation:\n",
        "\n",
        "**Peak at Prediction Start (Index 0):**\n",
        "- There is a significant peak in attention right at the prediction start point (index 0).\n",
        "    - Indicates that the most recent time step before making the prediction is extremely important for the model.\n",
        "        - Makes sense as the most recent data is likely to have the most impact on future predictions (e.g. weather, holidays, etc.)\n",
        "\n",
        "\n",
        "**Attention Decay:**\n",
        "- Attention weights gradually decrease as we move further away from the prediction point into the past.\n",
        "    - Suggests that more recent past information is more valuable for the model's predictions.\n",
        "\n",
        "\n",
        "**Cyclical Patterns:**\n",
        "- The attention plot exhibits some cyclical patterns, which could correspond to seasonal trends that the model has learned."
      ],
      "id": "872dcf5452e5c2a"
    },
    {
      "metadata": {
        "id": "36d6e4702496100b"
      },
      "cell_type": "markdown",
      "source": [
        "### 7.2.2. Attention per Horizon\n",
        "\n",
        "Provides insights into how the model's attention mechanism varies across different forecast horizons"
      ],
      "id": "36d6e4702496100b"
    },
    {
      "cell_type": "code",
      "id": "b8934fa1",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-06-12T13:11:07.354319Z",
          "start_time": "2024-06-12T13:11:06.998253Z"
        },
        "id": "b8934fa1"
      },
      "source": [
        "explainer.plot_attention(explainability_result, plot_type=\"all\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "76a4210e26218614"
      },
      "cell_type": "markdown",
      "source": [
        "### 7.2.2.1. Interpretation:\n",
        "\n",
        "**Peak Attention at Prediction Start (Index 0):**\n",
        "\n",
        "- Significant peak in attention right at the prediction start point (index 0) in all horizons.\n",
        "\n",
        "\n",
        "**Attention Decay:**\n",
        "\n",
        "- Further away from the prediction start point into the past, the attention weights generally decrease.\n",
        "    - Consistent across all horizons, suggesting that more recent past information is more valuable for the model's predictions.\n",
        "\n",
        "**Cyclical Patterns:**\n",
        "\n",
        "- There are noticeable cyclical patterns in attention weights for different horizons\n",
        "\n",
        "**Horizon-Specific Variations:**\n",
        "\n",
        "- While the general trend of peak attention at the prediction start point and decay over time holds for all horizons, there are some variations in the attention weights for different horizons. For example, some horizons show secondary peaks or fluctuations in attention at specific time steps, suggesting that certain historical periods are more influential for specific forecast horizons.\n"
      ],
      "id": "76a4210e26218614"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}