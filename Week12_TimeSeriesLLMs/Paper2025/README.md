https://arxiv.org/pdf/2502.07608

https://arxiv.org/pdf/2503.07649

https://arxiv.org/pdf/2503.08271

https://arxiv.org/pdf/2505.13192

https://arxiv.org/pdf/2505.24030

https://arxiv.org/pdf/2506.02081

https://arxiv.org/pdf/2506.08113

https://arxiv.org/pdf/2506.11040

https://www.mdpi.com/2571-9394/7/3/48

## Why Attention Fails: The Degeneration of Transformers into MLPs in Time Series Forecasting

https://arxiv.org/html/2509.20942v1#:~:text=Conclusion,-Report%20issue%20for&text=In%20this%20study%2C%20we%20unveil,their%20potential%20in%20this%20domain

## Why Do Transformers Fail to Forecast Time Series In-Context?

https://arxiv.org/html/2510.09776v1#:~:text=In%20this%20paper%2C%20we%20provide,sophisticated%20architectures%20without%20deeper%20scrutiny.&text=%E2%80%9CThe%20only%20thing%20we%20know,that%20it%20will%20be%20different.%E2%80%9D
